{
 "metadata": {
  "name": "",
  "signature": "sha256:25737f82c6b04ed7ba018d1a0ecf3409fe326c797627e226d9179f9570c210af"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lesson: Let's preprocess the data!\n",
      "\n",
      "## File I/O and exploring the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "f = '../data/census_data.csv'\n",
      "\n",
      "# read in the file\n",
      "\n",
      "\n",
      "# look at the first 5 lines\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What are the column names?\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sort the DataFrame by age and print out the last 5 lines\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Selecting columns and rows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a subset of the data with the columns education, occupation, hours_per_week. Look at the first 5 rows.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a subset of the data with the middle 50 rows and the columns work_class and race. Look at the first 5 rows.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a subset of the data where education_num is greater than 8 and where sex is equal to female. Look at the first 5 rows\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## groupby"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Group by work_class and output the group names (hint: add .keys() to the end of your line of code).\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's group by work_class and use the mean as the aggregate function\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pivoting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's pivot on education_num and sex, with hours_per_week as the values and mean as the aggfunc\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a pivot table of your choosing, with any columns for rows and cols and a numerical columns for values.\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Let's do the following:\n",
      "\n",
      "For the machine learning section, can you extract a subset of the data where:\n",
      "\n",
      "- native_country equals United-States\n",
      "- hours_per_week is greater than 10\n",
      "- age is greater than 20 and less than 50\n",
      "- education is Masters\n",
      "\n",
      "It's going to be a bunch of booleans!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Store that new dataframe in new_df and print out the first five rows.\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split the DataFrame so that all of the columns except the last one are in new_df_data, and the last one is in new_df_labels.\n",
      "\n",
      "new_df_data = new_df.iloc[:, :10]\n",
      "new_df_labels = new_df.iloc[:, -1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# For those using IPython Notebook/Wakari/NBViewer: Go to the scikit_learn notebook!\n",
      "\n",
      "# For those using code files, go to scikit_learn_materials.py!\n",
      "\n",
      "End of Pandas section.\n",
      "\n",
      "# Lesson: let's classify our data!\n",
      "\n",
      "## Final preprocessing touches\n",
      "\n",
      "Scikit-learn estimators take in continuous data only, which means that we'll have to transform our categorical data into something the scikit-learn estimators can handle. This is actually much easier than it sounds! We're going to convert our dataframe into a dictionary, and then encode the data in that dictionary into arrays of 1s and 0s.\n",
      "\n",
      "Let's first transform the dataframe into a dictionary. We first have to transpose our DataFrame, so there is one row per nested dictionary. Finally, we'll put each item into a list, because scikit-learn's DictVectorizer object takes a list of dictionaries to encode. We also only need the values from our list of dictionaries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_df_transpose = new_df_data.transpose()\n",
      "\n",
      "data_into_dict = new_df_transpose.to_dict()\n",
      "census_data = [v for k, v in data_into_dict.iteritems()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's encode those features and instances."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "dv = DictVectorizer()\n",
      "transformed_data = dv.fit_transform(census_data).toarray()\n",
      "transformed_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've done that, let's encode the labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "le = LabelEncoder()\n",
      "transformed_labels = le.fit_transform(new_df_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've done that, can you separate the transformed_data and transformed_labels into training and test sets?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's fit and predict both kNN and Naive Bayes to this data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "# fit both\n",
      "\n",
      "# predict\n",
      "\n",
      "\n",
      "# Outbpu kNN predictions on first 10 labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Output NB predictions on first 10 labels\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's cross validate each, and then I'll show you something cool you can do."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run cross-validation on kNN. Set cv=5\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run cross-validation on NB. Set cv=5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# For those using IPython Notebook/Wakari/NBViewer: Go to the matplotlib notebook!\n",
      "\n",
      "# For those using code files, go to matplotlib_materials.py!\n",
      "\n",
      "End of scikit-learn section.\n",
      "\n",
      "# Lesson: what can plots tell us about our data and results?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's look at the distribution of classes in our dataset. Can you get the value_counts of new_df_labels and make a bar chart?\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now, can you make a bar chat comparing the predicted kNN labels to the actual labels? You can use the first 10 only if you want."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What other visualizations would be helpful? Can you come up with a few more?\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}